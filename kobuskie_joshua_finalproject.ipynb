{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NJIT Fall 2024 CS634: Data Mining Final Project #\n",
    "## Joshua Kobuskie ##\n",
    "### November 17, 2024 ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Supervised Data Mining (Classification) Binary Classification Only #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement 3 different classification algorithms in Python. One of them is Random\n",
    "Forest , the second one is from the deep learning list in the “Appendix → Additional\n",
    "Option: Deep Learning”, and the third is from the list of algorithms in “Appendix →\n",
    "Additional Option: Algorithms” on 1 dataset of your choice (each of the three\n",
    "algorithms must run on the same dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This is not from scratch implementation, just use the existing libraries\n",
    "to implement the algorithms, but the performance metrics must be calculated\n",
    "manually. You may use “confusion_matrix” library to get TP, TN, FP, FN ONLY,\n",
    "then calculate the FPR, FNR, etc.… using the formulas from the slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources of data are listed in the Appendix “Additional Option: Sources of Data” or use\n",
    "your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your final term project documentation must clearly indicate the algorithms and dataset\n",
    "you used in the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification algorithms that I have chosen to implement and evaluate in this project are the Random Forest, the UNDECIDED, and the UNDECIDED.<br>\n",
    "The dataset I have chosen to use in this project is Kddcup 99 dataset from the scikit-learn real world datasets. This dataset contains TCP network connection data with about 5 million training records and 2 million test records. Each record is labelled as normal, or as a specific attack type. To ensure that this data will meet the criteria for binary classification used in this project, the data will be seperated into 2 classes of either normal or attack, rather than the specific classes of attacks detailed within the dataset. This also mimicks the intention of the dataset, as the training data contains 24 types of attack, but the test data contains an additonal 14 types of attacks not previously seen in the training data. This will test the models ability to detect known and unknown attacks based on its understnading of normal records. The models I will implment will be able to classify records as either normal TCP network connection data or abnormal TCP network connection data indicative of an attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the general submission rules and grading, include the websites where the\n",
    "software and complete dataset can be downloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scikit-learn software can be downloaded at the following link: https://scikit-learn.org/stable/install.html <br>\n",
    "The Kddcup 99 dataset can be downloaded in its entirety at the following link: https://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'bytes'>\n",
      "<class 'bytes'>\n",
      "<class 'bytes'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_kddcup99\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "dataset = fetch_kddcup99(as_frame=True).frame\n",
    "for col in dataset.iloc[0]:\n",
    "    print(type(col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains all the data needed for classification, but currently stores all of the protocol_type, service, flag, and labels as bytes. These values will be encoded into ints for training and testing. This data also presents a multiclassification problem. To transform this into a binary classification problem, we will have two class labels of normal and attack. All non-normal labels will be considered an attack for training and testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{b'tcp': 0, 0: b'tcp', b'udp': 1, 1: b'udp', b'icmp': 2, 2: b'icmp'}\n"
     ]
    }
   ],
   "source": [
    "def transformEncode(col, dict, count):\n",
    "    if col not in dict:\n",
    "        dict[col] = count[0]\n",
    "        dict[count[0]] = col\n",
    "        count[0] += 1\n",
    "    return dict[col]\n",
    "\n",
    "def transformLabel(col):\n",
    "    if col == b'normal.':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "protocolDict = {}\n",
    "#Must be a list so that a reference is passed and we can change the value outside the function\n",
    "count = [0]\n",
    "dataset[\"protocol_type\"] = dataset[\"protocol_type\"].apply(transformEncode, args=(protocolDict,count,))\n",
    "\n",
    "serviceDict = {}\n",
    "count = [0]\n",
    "dataset[\"service\"] = dataset[\"service\"].apply(transformEncode, args=(serviceDict,count,))\n",
    "\n",
    "flagDict = {}\n",
    "count = [0]\n",
    "dataset[\"flag\"] = dataset[\"flag\"].apply(transformEncode, args=(flagDict,count,))\n",
    "\n",
    "#Normal will be 0, attack will be 1\n",
    "labelDict = {b'normal':0, 0: b'normal', b'attack':1, 1:b'attack'}\n",
    "dataset[\"labels\"] = dataset[\"labels\"].apply(transformLabel)\n",
    "\n",
    "print(protocolDict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
